"""
ğŸ† JB DealScanner AI Service
ê²½ì§„ëŒ€íšŒìš© AI ë¶„ì„ ëª¨ë“ˆ - OpenAI GPT-4.1 Mini ì—°ë™
"""

import os
from typing import Dict, Optional
from dotenv import load_dotenv

# .env.local ë¡œë“œ
load_dotenv(".env.local")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    from openai import OpenAI
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    AI_AVAILABLE = True
except ImportError:
    client = None
    AI_AVAILABLE = False
    print("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜. pip install openai ì‹¤í–‰ í•„ìš”")


# ëª¨ë¸ ì„¤ì • (í…ŒìŠ¤íŠ¸ìš©: gpt-4.1-mini)
MODEL = "gpt-4.1-mini"


def generate_action_guide_ai(signal_type: str, company: str, news_content: str = "") -> Dict:
    """
    ğŸ† AI ê¸°ë°˜ RM/OPS ëŒ€ì‘ ê°€ì´ë“œ ìƒì„±
    """
    if not AI_AVAILABLE or not client:
        return _fallback_guide(signal_type, company)
    
    # ì‹œê·¸ë„ íƒ€ì…ë³„ ì»¨í…ìŠ¤íŠ¸
    context_map = {
        'LEGAL_CRISIS': 'ë²•ì  ìœ„ê¸° (íš¡ë ¹, ë°°ì„, ìˆ˜ì‚¬, ê²€ì°° ë“±)',
        'MARKET_CRISIS': 'ì‹œì¥ ìœ„ê¸° (ë¶€ë„, íŒŒì‚°, êµ¬ì¡°ì¡°ì •, ì‹ ìš©ë“±ê¸‰ í•˜ë½ ë“±)',
        'OPERATIONAL': 'ìš´ì˜ ë¦¬ìŠ¤í¬ (ì¼ë°˜ ëª¨ë‹ˆí„°ë§ í•„ìš”)'
    }
    
    context = context_map.get(signal_type, 'ì¼ë°˜ ë¦¬ìŠ¤í¬')
    
    prompt = f"""ë‹¹ì‹ ì€ ê¸ˆìœµê¸°ê´€ì˜ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    
ë‹¤ìŒ ìƒí™©ì— ëŒ€í•´ RM(ì˜ì—…ë‹´ë‹¹)ê³¼ OPS(ìš´ì˜ë‹´ë‹¹) ê°ê°ì—ê²Œ ì œê³µí•  ëŒ€ì‘ ê°€ì´ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

[ìƒí™©]
- ê¸°ì—…: {company}
- ë¦¬ìŠ¤í¬ ìœ í˜•: {context}
- ê´€ë ¨ ë‰´ìŠ¤: {news_content[:200] if news_content else 'ì—†ìŒ'}

[ìš”êµ¬ì‚¬í•­]
1. RM ì˜ì—… ê°€ì´ë“œ: 1-2ë¬¸ì¥ì˜ í•µì‹¬ ëŒ€ì‘ ë°©í–¥ (ê³µê²©ì /ì„ ì œì  ê´€ì )
2. RM To-Do: ì˜ì—… ë‹´ë‹¹ìê°€ ì¦‰ì‹œ ì‹¤í–‰í•  3ê°€ì§€ ì•¡ì…˜
3. OPS ë°©ì–´ ê°€ì´ë“œ: 1-2ë¬¸ì¥ì˜ í•µì‹¬ ëŒ€ì‘ ë°©í–¥ (ë°©ì–´ì /ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê´€ì )
4. OPS To-Do: ìš´ì˜ ë‹´ë‹¹ìê°€ ì¦‰ì‹œ ì‹¤í–‰í•  3ê°€ì§€ ì•¡ì…˜

[ì¶œë ¥ í˜•ì‹] ì •í™•íˆ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "rm_guide": "RM ê°€ì´ë“œ ë‚´ìš© (í•œê¸€, 50ì ì´ë‚´)",
    "rm_todos": ["ì•¡ì…˜1", "ì•¡ì…˜2", "ì•¡ì…˜3"],
    "ops_guide": "OPS ê°€ì´ë“œ ë‚´ìš© (í•œê¸€, 50ì ì´ë‚´)",
    "ops_todos": ["ì•¡ì…˜1", "ì•¡ì…˜2", "ì•¡ì…˜3"]
}}"""

    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸ˆìœµ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•­ìƒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=600,
            response_format={"type": "json_object"}
        )
        
        import json
        result = json.loads(response.choices[0].message.content)
        
        return {
            'rm_title': 'ğŸ’¡ RM ì˜ì—… ê°€ì´ë“œ (AI)',
            'rm_guide': f'"{result.get("rm_guide", "")}"',
            'rm_todos': result.get('rm_todos', ['ìŠ¤í°ì„œ ë©´ë‹´', 'ê³µë™ íˆ¬ìì í˜‘ì˜', 'M&A íƒìƒ‰']),
            'ops_title': 'ğŸ›¡ï¸ OPS ë°©ì–´ ê°€ì´ë“œ (AI)',
            'ops_guide': f'"{result.get("ops_guide", "")}"',
            'ops_todos': result.get('ops_todos', ['EOD í†µì§€ì„œ ì¤€ë¹„', 'ìì‚° ì ê²€', 'ë²•ë¬´ ê²€í† '])
        }
        
    except Exception as e:
        print(f"âš ï¸ AI ìƒì„± ì‹¤íŒ¨: {e}")
        return _fallback_guide(signal_type, company)


# ==============================================================================
# ğŸ† AI Action Guide v2.0 - ì‚°ì—…ë³„ ë§ì¶¤ ê°€ì´ë“œ (Day 4)
# ==============================================================================

# ì‚°ì—…ë³„ ì»¨í…ìŠ¤íŠ¸ ì •ì˜
INDUSTRY_CONTEXTS = {
    'ë°˜ë„ì²´': {
        'context': 'ë©”ëª¨ë¦¬ ê°€ê²© ë³€ë™, ì„¤ë¹„íˆ¬ì ë¦¬ìŠ¤í¬, ê¸€ë¡œë²Œ ìˆ˜ìš” ë³€í™”, ë¯¸ì¤‘ ê¸°ìˆ  ë¶„ìŸ',
        'key_risks': ['ì„¤ë¹„íˆ¬ì ì§€ì—°', 'ìˆ˜ìš” ê¸‰ê°', 'ì¬ê³  ê¸‰ì¦', 'ê¸°ìˆ  ì œì¬'],
        'rm_focus': 'ê¸€ë¡œë²Œ ê³ ê°ì‚¬ ë‹¤ë³€í™”, ì„ ì œì  ì¬ê³  ê´€ë¦¬, ê¸°ìˆ  ê²½ìŸë ¥ í™•ë³´',
        'ops_focus': 'Capex ëª¨ë‹ˆí„°ë§, ì¬ê³  íšŒì „ìœ¨ ì ê²€, ê°€ë™ë¥  ì¶”ì '
    },
    'ê¸ˆìœµ': {
        'context': 'ê¸ˆë¦¬ ë³€ë™, ê·œì œ ë¦¬ìŠ¤í¬, ì‹ ìš© ë¦¬ìŠ¤í¬, ìœ ë™ì„± ë¦¬ìŠ¤í¬',
        'key_risks': ['ê¸ˆë¦¬ ê¸‰ë³€', 'NPL ê¸‰ì¦', 'ê·œì œ ì œì¬', 'ìœ ë™ì„± ìœ„ê¸°'],
        'rm_focus': 'ê¸ˆë¦¬ í—¤ì§€, í¬íŠ¸í´ë¦¬ì˜¤ ë‹¤ê°í™”, ê·œì œ ì¤€ìˆ˜ ê°•í™”',
        'ops_focus': 'BIS ë¹„ìœ¨ ì ê²€, LCR/NSFR ëª¨ë‹ˆí„°ë§, ì¶©ë‹¹ê¸ˆ ì ì •ì„±'
    },
    'ê±´ì„¤': {
        'context': 'ë¶€ë™ì‚° ê²½ê¸°, ë¶„ì–‘ë¥ , ìê¸ˆ ì¡°ë‹¬, PF ë¦¬ìŠ¤í¬',
        'key_risks': ['ë¯¸ë¶„ì–‘ ì¦ê°€', 'PF ì—°ì¥ ë¶ˆê°€', 'ìì¬ë¹„ ê¸‰ë“±', 'ì›ê°€ìœ¨ ì•…í™”'],
        'rm_focus': 'ë¶„ì–‘ ì´‰ì§„, ìê¸ˆ ì¡°ë‹¬ ëŒ€ì•ˆ, í˜‘ë ¥ì‚¬ ë¦¬ìŠ¤í¬ ê´€ë¦¬',
        'ops_focus': 'ë¯¸ë¶„ì–‘ ëª¨ë‹ˆí„°ë§, ì›ê°€ìœ¨ ì¶”ì , PF ë§Œê¸° ê´€ë¦¬'
    },
    'ìœ í†µ': {
        'context': 'ì†Œë¹„ íŠ¸ë Œë“œ, ì˜¨ë¼ì¸ ì „í™˜, ë¬¼ë¥˜ íš¨ìœ¨ì„±, ì¬ê³  ê´€ë¦¬',
        'key_risks': ['ì†Œë¹„ ìœ„ì¶•', 'ì˜¨ë¼ì¸ ê²½ìŸ', 'ë¬¼ë¥˜ë¹„ ê¸‰ë“±', 'íì  ì¦ê°€'],
        'rm_focus': 'ì±„ë„ ë‹¤ê°í™”, ë¬¼ë¥˜ íš¨ìœ¨í™”, ê³ ê° ë°ì´í„° í™œìš©',
        'ops_focus': 'ë§¤ì¶œ/ë§¤ì¥ ì¶”ì´, ì¬ê³  íšŒì „ìœ¨, ì„ëŒ€ë£Œ ë¶€ë‹´ë¥ '
    },
    'ê¸°íƒ€': {
        'context': 'ì¼ë°˜ ì‚¬ì—… ë¦¬ìŠ¤í¬, ê²½ê¸° ë³€ë™, ê²½ìŸ ì‹¬í™”',
        'key_risks': ['ë§¤ì¶œ ê°ì†Œ', 'ë¹„ìš© ì¦ê°€', 'ê²½ìŸ ì‹¬í™”', 'ê·œì œ ë³€í™”'],
        'rm_focus': 'ê³ ê° ìœ ì§€, ë¹„ìš© íš¨ìœ¨í™”, ì‹ ê·œ ì‹œì¥ ê°œì²™',
        'ops_focus': 'ì†ìµ ëª¨ë‹ˆí„°ë§, í˜„ê¸ˆíë¦„ ì¶”ì , ì£¼ìš” ê³„ì•½ ê´€ë¦¬'
    }
}


def detect_industry(company: str) -> str:
    """ê¸°ì—…ëª…ì—ì„œ ì‚°ì—… ë¶„ë¥˜ ì¶”ì •"""
    if any(kw in company for kw in ['ì€í–‰', 'ê¸ˆìœµ', 'ìºí”¼íƒˆ', 'ì¹´ë“œ', 'ì €ì¶•', 'ë³´í—˜', 'ì¦ê¶Œ']):
        return 'ê¸ˆìœµ'
    if any(kw in company for kw in ['ë°˜ë„ì²´', 'í•˜ì´ë‹‰ìŠ¤', 'ì‚¼ì„±ì „ì', 'SK', 'ë§ˆì´í¬ë¡ ', 'ë©”ëª¨ë¦¬']):
        return 'ë°˜ë„ì²´'
    if any(kw in company for kw in ['ê±´ì„¤', 'ê±´ì¶•', 'E&C', 'ì—”ì§€ë‹ˆì–´ë§', 'ì£¼íƒ', 'ê°œë°œ']):
        return 'ê±´ì„¤'
    if any(kw in company for kw in ['ìœ í†µ', 'ë§ˆíŠ¸', 'ë°±í™”ì ', 'ì‡¼í•‘', 'ë¦¬í…Œì¼', 'í¸ì˜ì ']):
        return 'ìœ í†µ'
    return 'ê¸°íƒ€'


def generate_action_guide_ai_v2(
    signal_type: str, 
    company: str, 
    industry: str = None,
    news_content: str = "",
    risk_score: int = 0
) -> Dict:
    """
    ğŸ† AI Action Guide v2.0 - ì‚°ì—…ë³„ ë§ì¶¤ ê°€ì´ë“œ ìƒì„±
    
    Args:
        signal_type: LEGAL_CRISIS, MARKET_CRISIS, OPERATIONAL
        company: ê¸°ì—…ëª…
        industry: ì‚°ì—… ë¶„ë¥˜ (Noneì´ë©´ ìë™ ê°ì§€)
        news_content: ê´€ë ¨ ë‰´ìŠ¤ ë‚´ìš©
        risk_score: í˜„ì¬ ë¦¬ìŠ¤í¬ ì ìˆ˜
    """
    if not AI_AVAILABLE or not client:
        return _fallback_guide_v2(signal_type, company, industry)
    
    # ì‚°ì—… ìë™ ê°ì§€
    if not industry:
        industry = detect_industry(company)
    
    ind_ctx = INDUSTRY_CONTEXTS.get(industry, INDUSTRY_CONTEXTS['ê¸°íƒ€'])
    
    # ì‹œê·¸ë„ íƒ€ì…ë³„ ì»¨í…ìŠ¤íŠ¸
    signal_context = {
        'LEGAL_CRISIS': 'ë²•ì  ìœ„ê¸° (íš¡ë ¹, ë°°ì„, ìˆ˜ì‚¬, ê²€ì°° ë“±)',
        'MARKET_CRISIS': 'ì‹œì¥ ìœ„ê¸° (ë¶€ë„, íŒŒì‚°, êµ¬ì¡°ì¡°ì •, ì‹ ìš©ë“±ê¸‰ í•˜ë½ ë“±)',
        'OPERATIONAL': 'ìš´ì˜ ë¦¬ìŠ¤í¬ (ì¼ë°˜ ëª¨ë‹ˆí„°ë§ í•„ìš”)'
    }.get(signal_type, 'ì¼ë°˜ ë¦¬ìŠ¤í¬')
    
    prompt = f"""ë‹¹ì‹ ì€ ê¸ˆìœµê¸°ê´€ì˜ {industry} ì‚°ì—… ì „ë¬¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬ìì…ë‹ˆë‹¤.

[ì‚°ì—… ì»¨í…ìŠ¤íŠ¸: {industry}]
- ì£¼ìš” ë¦¬ìŠ¤í¬ ìš”ì¸: {ind_ctx['context']}
- í•µì‹¬ ìœ„í—˜ ì§€í‘œ: {', '.join(ind_ctx['key_risks'])}

[í˜„ì¬ ìƒí™©]
- ê¸°ì—…: {company}
- ë¦¬ìŠ¤í¬ ìœ í˜•: {signal_context}
- ë¦¬ìŠ¤í¬ ì ìˆ˜: {risk_score}ì  (100ì  ë§Œì )
- ê´€ë ¨ ë‰´ìŠ¤: {news_content[:300] if news_content else 'ì—†ìŒ'}

[{industry} ì‚°ì—… íŠ¹í™” ê°€ì´ë“œ ìš”ì²­]
1. RM ì˜ì—… ê°€ì´ë“œ: {industry} ì‚°ì—… íŠ¹ì„±ì„ ë°˜ì˜í•œ ì„ ì œì  ëŒ€ì‘ ë°©í–¥
2. RM To-Do: {industry} ì‚°ì—… íŠ¹í™” 3ê°€ì§€ ì•¡ì…˜ ì•„ì´í…œ
3. OPS ë°©ì–´ ê°€ì´ë“œ: {industry} ì‚°ì—… íŠ¹ì„±ì„ ë°˜ì˜í•œ ë°©ì–´ì  ëŒ€ì‘ ë°©í–¥
4. OPS To-Do: {industry} ì‚°ì—… íŠ¹í™” 3ê°€ì§€ ì ê²€ í•­ëª©

[ì¶œë ¥ í˜•ì‹] JSON:
{{
    "rm_guide": "RM ê°€ì´ë“œ (50ì ì´ë‚´)",
    "rm_todos": ["ì•¡ì…˜1", "ì•¡ì…˜2", "ì•¡ì…˜3"],
    "ops_guide": "OPS ê°€ì´ë“œ (50ì ì´ë‚´)",
    "ops_todos": ["ì•¡ì…˜1", "ì•¡ì…˜2", "ì•¡ì…˜3"],
    "industry_insight": "{industry} ì‚°ì—… íŠ¹í™” ì¸ì‚¬ì´íŠ¸ (30ì)"
}}"""

    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": f"ë‹¹ì‹ ì€ {industry} ì‚°ì—… ì „ë¬¸ ê¸ˆìœµ ë¦¬ìŠ¤í¬ ê´€ë¦¬ìì…ë‹ˆë‹¤. JSONë§Œ ì‘ë‹µ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=700,
            response_format={"type": "json_object"}
        )
        
        import json
        result = json.loads(response.choices[0].message.content)
        
        return {
            'rm_title': f'ğŸ’¡ RM ì˜ì—… ê°€ì´ë“œ (AI v2.0 - {industry})',
            'rm_guide': f'"{result.get("rm_guide", "")}"',
            'rm_todos': result.get('rm_todos', ['ê³ ê° ë©´ë‹´', 'ë¦¬ìŠ¤í¬ ê³µìœ ', 'ëŒ€ì•ˆ ê²€í† ']),
            'ops_title': f'ğŸ›¡ï¸ OPS ë°©ì–´ ê°€ì´ë“œ (AI v2.0 - {industry})',
            'ops_guide': f'"{result.get("ops_guide", "")}"',
            'ops_todos': result.get('ops_todos', ['í˜„í™© ì ê²€', 'ì¶©ë‹¹ê¸ˆ ê²€í† ', 'ë³´ê³ ì„œ ì‘ì„±']),
            'industry': industry,
            'industry_insight': result.get('industry_insight', f'{industry} ì‚°ì—… íŠ¹í™” ë¶„ì„')
        }
        
    except Exception as e:
        print(f"âš ï¸ AI v2.0 ìƒì„± ì‹¤íŒ¨: {e}")
        return _fallback_guide_v2(signal_type, company, industry)


def _fallback_guide_v2(signal_type: str, company: str, industry: str = None) -> Dict:
    """AI í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì‚°ì—…ë³„ ê¸°ë³¸ ê°€ì´ë“œ"""
    if not industry:
        industry = detect_industry(company)
    
    ind_ctx = INDUSTRY_CONTEXTS.get(industry, INDUSTRY_CONTEXTS['ê¸°íƒ€'])
    
    return {
        'rm_guide': f"{ind_ctx['rm_focus'][:20]}... (ê¸°ë³¸)",
        'rm_todos': ind_ctx['key_risks'][:3],
        'ops_guide': f"{ind_ctx['ops_focus'][:20]}... (ê¸°ë³¸)",
        'ops_todos': ['í˜„í™© ì ê²€', 'ì¶©ë‹¹ê¸ˆ ê²€í† ', 'ë³´ê³ ì„œ ì‘ì„±'],
        'industry_insight': f'{industry} ì‚°ì—… ê¸°ë³¸ ê°€ì´ë“œ',
        # í˜¸í™˜ì„± í•„ë“œ
        'rm_title': f'ğŸ’¡ RM ì˜ì—… ê°€ì´ë“œ ({industry})',
        'ops_title': f'ğŸ›¡ï¸ OPS ë°©ì–´ ê°€ì´ë“œ ({industry})',
        'industry': industry
    }


def predict_risk_trajectory(company: str, current_score: int, recent_news_summary: str) -> Dict:
    """
    ğŸ”® [New] AI ê¸°ë°˜ ë¯¸ë˜ ë¦¬ìŠ¤í¬ ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡ (Predictive AI)
    """
    if not AI_AVAILABLE or not client:
        return _fallback_prediction(company)

    prompt = f"""ë‹¹ì‹ ì€ ê¸ˆìœµ ë¦¬ìŠ¤í¬ ì˜ˆì¸¡ ëª¨ë¸ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ê¸°ì—…ì˜ í˜„ì¬ ë¦¬ìŠ¤í¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥í›„ 1ê°œì›” ë‚´ ì˜ˆìƒë˜ëŠ” ë¦¬ìŠ¤í¬ ì „ê°œ ë°©í–¥(Trajectory)ì„ 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”.

[ê¸°ì—… ì •ë³´]
- ê¸°ì—…: {company}
- í˜„ì¬ ë¦¬ìŠ¤í¬ ì ìˆ˜: {current_score}ì  (100ì  ë§Œì , ë†’ì„ìˆ˜ë¡ ìœ„í—˜)
- ìµœê·¼ ë‰´ìŠ¤ ìš”ì•½: {recent_news_summary[:300]}

[ìš”êµ¬ì‚¬í•­]
í–¥í›„ 4ì£¼ê°„ ë°œìƒ ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ 'Best', 'Base', 'Worst' ì¼€ì´ìŠ¤ë¡œ ë‚˜ëˆ„ì–´ ì˜ˆì¸¡.
ê° ì‹œë‚˜ë¦¬ì˜¤ëŠ” "í•µì‹¬ ì´ë²¤íŠ¸"ì™€ "ì˜ˆìƒ ë¦¬ìŠ¤í¬ ì ìˆ˜"ë¥¼ í¬í•¨í•´ì•¼ í•¨.

[ì¶œë ¥ í˜•ì‹] JSON:
{{
    "trend": "ìƒìŠ¹ì„¸" or "í•˜ë½ì„¸" or "ë³€ë™ì„± í™•ëŒ€",
    "scenarios": {{
        "best": {{ "event": "ì´ë²¤íŠ¸ ì„¤ëª… (20ì)", "prob": "20%", "score": 30 }},
        "base": {{ "event": "ì´ë²¤íŠ¸ ì„¤ëª… (20ì)", "prob": "60%", "score": 50 }},
        "worst": {{ "event": "ì´ë²¤íŠ¸ ì„¤ëª… (20ì)", "prob": "20%", "score": 80 }}
    }}
}}"""

    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "ê¸ˆìœµ ë¦¬ìŠ¤í¬ ì˜ˆì¸¡ ëª¨ë¸. JSON ì‘ë‹µ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500,
            response_format={"type": "json_object"}
        )
        import json
        return json.loads(response.choices[0].message.content)
    except Exception:
        return _fallback_prediction(company)


def _fallback_guide(signal_type: str, company: str) -> Dict:
    """AI í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê°€ì´ë“œ (ë£° ê¸°ë°˜)"""
    GUIDES = {
        'LEGAL_CRISIS': {
            'rm_title': 'ğŸ’¡ RM ì˜ì—… ê°€ì´ë“œ',
            'rm_guide': '"ìŠ¤í°ì„œ ë¶€ë„ ë¦¬ìŠ¤í¬ ì‹¬í™”, ì‹ ê·œ ëŒ€ì¶œ ì¤‘ë‹¨ ë° ê¸°ì¡´ ìê¸ˆ ì ê²€ í•„ìš”."',
            'rm_todos': ['ìŠ¤í°ì„œ ìê¸ˆ ê´€ë¦¬ì¸ ë©´ë‹´', 'ê³µë™ íˆ¬ìì ë¦¬ìŠ¤í¬ ë¶„ë‹´ íƒ€ì§„', 'White Knight íƒìƒ‰'],
            'ops_title': 'ğŸ›¡ï¸ OPS ë°©ì–´ ê°€ì´ë“œ',
            'ops_guide': '"ê¸ˆìœµì•½ì • ìœ„ë°˜ EOD í†µì§€ì„œ ì‘ì„±, ê³„ì¢Œ ëª¨ë‹ˆí„°ë§ ë° ìê¸ˆ ì´íƒˆ ì°¨ë‹¨."',
            'ops_todos': ['â˜‘ EOD í†µì§€ì„œ ë°œì†¡ ì¤€ë¹„', 'ìì‚° í˜„í™© ì¬ì ê²€', 'ë²•ë¬´ë²•ì¸ ì„ ì„']
        },
        'MARKET_CRISIS': {
            'rm_title': 'ğŸ’¡ RM ì˜ì—… ê°€ì´ë“œ',
            'rm_guide': f'"{company} ì‹œì¥ ìœ„ê¸° ê°ì§€. í—¤ì§€ í¬ì§€ì…˜ ë° ìœ ë™ì„± í™•ë³´ ê²€í† ."',
            'rm_todos': ['ì‹œì¥ ë™í–¥ ëª¨ë‹ˆí„°ë§ ê°•í™”', 'ìœ ë™ì„± í™•ë³´ ë°©ì•ˆ ê²€í† ', 'íŒŒíŠ¸ë„ˆì‚¬ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜'],
            'ops_title': 'ğŸ›¡ï¸ OPS ë°©ì–´ ê°€ì´ë“œ',
            'ops_guide': '"LTV í•œë„ ì¬ê²€í†  ë° ì¶”ê°€ ë‹´ë³´ ìš”ì²­. ì‹œì¥ ë³€ë™ì„± ëŒ€ì‘ ì‹œë‚˜ë¦¬ì˜¤."',
            'ops_todos': ['ë‹´ë³´ ê°€ì¹˜ ì¬í‰ê°€', 'Covenant ìœ„ë°˜ ì ê²€', 'ë¹„ìƒ ìœ ë™ì„± í™•ë³´']
        },
        'OPERATIONAL': {
            'rm_title': 'ğŸ’¡ RM ì˜ì—… ê°€ì´ë“œ',
            'rm_guide': f'"{company} ìš´ì˜ ë¦¬ìŠ¤í¬ ì£¼ì˜. ì •ê¸° ëª¨ë‹ˆí„°ë§ ë° ê²½ì˜ì§„ ë©´ë‹´ ê¶Œì¥."',
            'rm_todos': ['ì •ê¸° ê²½ì˜ ë³´ê³ ì„œ ê²€í† ', 'í˜„ì¥ ì‹¤ì‚¬ ì¼ì • ì¡°ìœ¨', 'ê²½ì˜ì§„ ë©´ë‹´ ìš”ì²­'],
            'ops_title': 'ğŸ›¡ï¸ OPS ë°©ì–´ ê°€ì´ë“œ',
            'ops_guide': '"ë‚´ë¶€ í†µì œ ì ê²€ ë° ìš´ì˜ íš¨ìœ¨ì„± ë¶„ì„. ì´ìƒ ì§•í›„ ë°œê²¬ ì‹œ ì¦‰ì‹œ ë³´ê³ ."',
            'ops_todos': ['ë‚´ë¶€ ê°ì‚¬ ê²°ê³¼ í™•ì¸', 'ìš´ì˜ íš¨ìœ¨ì„± ë¶„ì„', 'IT ë³´ì•ˆ ì ê²€']
        }
    }
    return GUIDES.get(signal_type, GUIDES['OPERATIONAL'])


def classify_timeline_event_ai(event_title: str, event_date: str = "") -> Dict:
    """
    ğŸ† AI ê¸°ë°˜ íƒ€ì„ë¼ì¸ ì´ë²¤íŠ¸ 3ë‹¨ê³„ ë¶„ë¥˜
    """
    if not AI_AVAILABLE or not client:
        return _fallback_classify(event_title)
    
    prompt = f"""ë‹¹ì‹ ì€ ê¸ˆìœµ ë¦¬ìŠ¤í¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‰´ìŠ¤ ì œëª©ì„ ë¶„ì„í•˜ì—¬ ë¦¬ìŠ¤í¬ ë‹¨ê³„ë¥¼ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

[ë‰´ìŠ¤ ì œëª©]
{event_title}

[3ë‹¨ê³„ ë¶„ë¥˜ ê¸°ì¤€]
- Stage 1 (ë‰´ìŠ¤ ë³´ë„): ì–¸ë¡  ìµœì´ˆ ë³´ë„, ë£¨ë¨¸, í™•ì¸ë˜ì§€ ì•Šì€ ì •ë³´
- Stage 2 (ê¸ˆìœµìœ„ í†µì§€): ê¸ˆìœµë‹¹êµ­/ê²€ì°°/ê³µì •ìœ„ ê°œì…, ìˆ˜ì‚¬, ì¡°ì‚¬, ì œì¬, ê³¼ì§•ê¸ˆ
- Stage 3 (ëŒ€ì£¼ë‹¨ í™•ì¸): ëŒ€ì£¼ë‹¨/ì±„ê¶Œë‹¨ ê°œì…, ìƒí™˜ ìš”êµ¬, ì›Œí¬ì•„ì›ƒ, EOD, ì±„ë¬´ ê´€ë ¨

[ì¶œë ¥ í˜•ì‹] ì •í™•íˆ ë‹¤ìŒ JSON í˜•ì‹:
{{
    "stage": 1,
    "stage_label": "ë‰´ìŠ¤ ë³´ë„",
    "description": "ì„ í–‰ ê°ì§€ ì™„ë£Œ (20ì ì´ë‚´ ì„¤ëª…)"
}}"""

    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "ê¸ˆìœµ ë¦¬ìŠ¤í¬ ë¶„ë¥˜ ì „ë¬¸ê°€. JSONë§Œ ì‘ë‹µ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=150,
            response_format={"type": "json_object"}
        )
        
        import json
        result = json.loads(response.choices[0].message.content)
        
        stage = result.get('stage', 1)
        icons = {1: 'ğŸ”µ', 2: 'ğŸŸ¡', 3: 'ğŸ”´'}
        
        return {
            "stage": stage,
            "stage_label": result.get('stage_label', 'ë‰´ìŠ¤ ë³´ë„'),
            "icon": icons.get(stage, 'ğŸ”µ'),
            "description": result.get('description', 'ë¦¬ìŠ¤í¬ ê°ì§€')
        }
        
    except Exception as e:
        return _fallback_classify(event_title)


def _fallback_classify(event_title: str) -> Dict:
    """AI ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜"""
    STAGE_KEYWORDS = {
        'stage3': ['ëŒ€ì£¼ë‹¨', 'ì±„ê¶Œë‹¨', 'ìƒí™˜', 'ë§Œê¸°', 'EOD', 'ê¸°í•œì´ìµ', 'ì›Œí¬ì•„ì›ƒ', 'ì±„ë¬´'],
        'stage2': ['ê¸ˆìœµìœ„', 'ê¸ˆê°ì›', 'ê²€ì°°', 'ìˆ˜ì‚¬', 'ì¡°ì‚¬', 'ì œì¬', 'ê³¼ì§•ê¸ˆ', 'ê¸°ì†Œ']
    }
    
    for kw in STAGE_KEYWORDS['stage3']:
        if kw in event_title:
            return {"stage": 3, "stage_label": "ëŒ€ì£¼ë‹¨ í™•ì¸", "icon": "ğŸ”´", "description": "ë‹´ë‹¹ì ì¡°ì¹˜ í•„ìš”"}
    
    for kw in STAGE_KEYWORDS['stage2']:
        if kw in event_title:
            return {"stage": 2, "stage_label": "ê¸ˆìœµìœ„ í†µì§€", "icon": "ğŸŸ¡", "description": "ê·œì œ ë¦¬ìŠ¤í¬ ë°œìƒ"}
    
    return {"stage": 1, "stage_label": "ë‰´ìŠ¤ ë³´ë„", "icon": "ğŸ”µ", "description": "ì„ í–‰ ê°ì§€ ì™„ë£Œ"}


def _fallback_prediction(company: str) -> Dict:
    return {
        "trend": "ë³€ë™ì„± í™•ëŒ€",
        "scenarios": {
            "best": {"event": "ë¦¬ìŠ¤í¬ ìš”ì¸ í•´ì†Œ", "prob": "20%", "score": 30},
            "base": {"event": "í˜„ ìƒíƒœ ìœ ì§€", "prob": "60%", "score": 50},
            "worst": {"event": "ì¶”ê°€ ì•…ì¬ ë°œìƒ", "prob": "20%", "score": 80}
        }
    }


def analyze_timeline_with_ai(events: list) -> list:
    """
    ğŸ† ì—¬ëŸ¬ ì´ë²¤íŠ¸ë¥¼ í•œë²ˆì— AIë¡œ ë¶„ì„ (ë°°ì¹˜ ì²˜ë¦¬)
    """
    if not AI_AVAILABLE or not client or not events:
        return [_fallback_classify(e.get('title', '')) for e in events]
    
    # ì´ë²¤íŠ¸ ëª©ë¡ ì •ë¦¬
    event_texts = "\n".join([f"{i+1}. {e.get('title', '')[:60]}" for i, e in enumerate(events[:5])])
    
    prompt = f"""ë‹¤ìŒ ë‰´ìŠ¤ ì œëª©ë“¤ì„ ê°ê° ë¦¬ìŠ¤í¬ ë‹¨ê³„ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

[ë‰´ìŠ¤ ëª©ë¡]
{event_texts}

[3ë‹¨ê³„ ë¶„ë¥˜ ê¸°ì¤€]
- Stage 1: ì–¸ë¡  ìµœì´ˆ ë³´ë„
- Stage 2: ê¸ˆìœµë‹¹êµ­/ê²€ì°° ê°œì…
- Stage 3: ëŒ€ì£¼ë‹¨/ì±„ê¶Œë‹¨ ê°œì…

[ì¶œë ¥ í˜•ì‹] JSON:
{{
    "classifications": [
        {{"index": 1, "stage": 1, "stage_label": "ë‰´ìŠ¤ ë³´ë„", "description": "ì„¤ëª…"}},
        ...
    ]
}}"""

    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "ê¸ˆìœµ ë¦¬ìŠ¤í¬ ë¶„ë¥˜ ì „ë¬¸ê°€. JSONë§Œ ì‘ë‹µ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=600,
            response_format={"type": "json_object"}
        )
        
        import json
        result = json.loads(response.choices[0].message.content)
        classifications = result.get('classifications', [])
        
        icons = {1: 'ğŸ”µ', 2: 'ğŸŸ¡', 3: 'ğŸ”´'}
        
        output = []
        for i, event in enumerate(events[:5]):
            if i < len(classifications):
                c = classifications[i]
                stage = c.get('stage', 1)
                output.append({
                    "stage": stage,
                    "stage_label": c.get('stage_label', 'ë‰´ìŠ¤ ë³´ë„'),
                    "icon": icons.get(stage, 'ğŸ”µ'),
                    "description": c.get('description', 'ë¦¬ìŠ¤í¬ ê°ì§€')
                })
            else:
                output.append(_fallback_classify(event.get('title', '')))
        
        return output
        
    except Exception as e:
        return [_fallback_classify(e.get('title', '')) for e in events]


def analyze_risk_with_ai(company: str, news_list: list, score: int) -> str:
    """
    ğŸ† AI ê¸°ë°˜ ì¢…í•© ë¦¬ìŠ¤í¬ ë¶„ì„ ì½”ë©˜íŠ¸ ìƒì„±
    """
    if not AI_AVAILABLE or not client:
        return f"{company}: ë¦¬ìŠ¤í¬ ì ìˆ˜ {score}ì . ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ í•„ìš”."
    
    news_summary = "\n".join([f"- {n.get('title', '')[:50]}" for n in news_list[:3]])
    
    prompt = f"""ë‹¤ìŒ ê¸°ì—…ì˜ ë¦¬ìŠ¤í¬ ìƒí™©ì„ 1-2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ê¸°ì—…: {company}
ë¦¬ìŠ¤í¬ ì ìˆ˜: {score}ì  (100ì  ë§Œì )
ìµœê·¼ ë‰´ìŠ¤:
{news_summary}

ìš”ì•½ (í•œê¸€, 50ì ì´ë‚´, ì „ë¬¸ê°€ í†¤):"""

    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸ˆìœµ ë¦¬ìŠ¤í¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê²Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
            max_tokens=100
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"{company}: ë¦¬ìŠ¤í¬ ì ìˆ˜ {score}ì . ëª¨ë‹ˆí„°ë§ í•„ìš”."


# ==============================================================================
# ğŸ† Text2Cypher - ìì—°ì–´ â†’ Cypher ì¿¼ë¦¬ ë³€í™˜ (Day 3)
# ==============================================================================

# ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ ì •ì˜ (Text2Cypher AI í”„ë¡¬í”„íŠ¸ìš©)
GRAPH_SCHEMA = """
## Neo4j Graph Schema

### Nodes
- (:Company {name: STRING, corp_code: STRING, total_score: INT, propagated_risk: INT})
- (:Person {name: STRING})
- (:Category {id: STRING, type: STRING, label: STRING, score: INT})
- (:NewsCategory {id: STRING, type: STRING, label: STRING})
- (:DisclosureCategory {id: STRING, type: STRING, label: STRING, count: INT, risk_score: INT})
- (:NewsArticle {url: STRING, title: STRING, date: STRING, source: STRING, risk_score: INT, sentiment: STRING})
- (:Disclosure {code: STRING, title: STRING, date: STRING, category: STRING, risk_score: INT})
- (:RiskLevel {level: STRING, label: STRING})  # level: GREEN, YELLOW, RED

### Relationships
- (:RiskLevel)-[:HAS_STATUS]->(:Company)
- (:Company)-[:HAS_CATEGORY]->(:Category)
- (:Category)-[:HAS_SUBCATEGORY]->(:NewsCategory|:DisclosureCategory)
- (:Category)-[:CONTAINS]->(:Person)
- (:NewsCategory)-[:HAS_ARTICLE]->(:NewsArticle)
- (:DisclosureCategory)-[:HAS_DISCLOSURE]->(:Disclosure)

### Key Properties
- Company.total_score: ë¦¬ìŠ¤í¬ ì´ì  (0-100, ë†’ì„ìˆ˜ë¡ ìœ„í—˜)
- RiskLevel.level: GREEN(ì •ìƒ), YELLOW(ì£¼ì˜), RED(ìœ„í—˜)
- NewsArticle.sentiment: ë¶€ì •, ì¤‘ë¦½, ê¸ì •
"""


def text2cypher(question: str, graph=None) -> Dict:
    """
    ğŸ† Text2Cypher - ìì—°ì–´ ì§ˆë¬¸ì„ Cypher ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ê³  ì‹¤í–‰
    
    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸ (í•œêµ­ì–´)
        graph: Neo4jGraph ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ë‚´ë¶€ì—ì„œ ìƒì„±)
    
    Returns:
        {
            "question": ì›ë³¸ ì§ˆë¬¸,
            "cypher": ìƒì„±ëœ Cypher ì¿¼ë¦¬,
            "results": ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼,
            "answer": ìì—°ì–´ ì‘ë‹µ,
            "success": ì„±ê³µ ì—¬ë¶€
        }
    """
    if not AI_AVAILABLE or not client:
        return {
            "question": question,
            "cypher": None,
            "results": None,
            "answer": "âš ï¸ AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "success": False
        }
    
    # Cypher ìƒì„± í”„ë¡¬í”„íŠ¸
    prompt = f"""ë‹¹ì‹ ì€ Neo4j Cypher ì¿¼ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ Cypher ì¿¼ë¦¬ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

{GRAPH_SCHEMA}

## Rules
1. ì½ê¸° ì „ìš© ì¿¼ë¦¬ë§Œ ìƒì„± (MATCH, RETURN, WHERE, ORDER BY, LIMIT)
2. CREATE, DELETE, SET, MERGE ë“± ì“°ê¸° ëª…ë ¹ ì ˆëŒ€ ê¸ˆì§€
3. ì •ë ¬ ì‹œ ë°˜ë“œì‹œ IS NOT NULL ì²´í¬ ì¶”ê°€
4. ê²°ê³¼ëŠ” ìµœëŒ€ 20ê°œë¡œ ì œí•œ (LIMIT 20)
5. í•œêµ­ì–´ ì†ì„±ê°’ ê²€ìƒ‰ ì‹œ ì •í™•í•œ ê°’ ì‚¬ìš©

## ì‚¬ìš©ì ì§ˆë¬¸
{question}

## ì¶œë ¥ í˜•ì‹ (JSONë§Œ ì‘ë‹µ)
{{
    "cypher": "MATCH (c:Company) WHERE c.name = 'SKí•˜ì´ë‹‰ìŠ¤' RETURN c.total_score AS score",
    "explanation": "SKí•˜ì´ë‹‰ìŠ¤ì˜ ë¦¬ìŠ¤í¬ ì ìˆ˜ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."
}}"""

    try:
        # 1. Cypher ì¿¼ë¦¬ ìƒì„±
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "Neo4j Cypher ì „ë¬¸ê°€. JSONë§Œ ì‘ë‹µ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=500,
            response_format={"type": "json_object"}
        )
        
        import json
        result = json.loads(response.choices[0].message.content)
        cypher = result.get("cypher", "")
        explanation = result.get("explanation", "")
        
        # 2. ì•ˆì „ì„± ê²€ì¦ (ì½ê¸° ì „ìš©ë§Œ í—ˆìš©)
        cypher_upper = cypher.upper()
        forbidden = ["CREATE", "DELETE", "SET ", "MERGE", "REMOVE", "DROP", "DETACH"]
        for kw in forbidden:
            if kw in cypher_upper:
                return {
                    "question": question,
                    "cypher": cypher,
                    "results": None,
                    "answer": f"âš ï¸ ì½ê¸° ì „ìš© ì¿¼ë¦¬ë§Œ í—ˆìš©ë©ë‹ˆë‹¤. ({kw} ê°ì§€)",
                    "success": False
                }
        
        # 3. Neo4j ì—°ê²° ë° ì¿¼ë¦¬ ì‹¤í–‰
        if graph is None:
            from langchain_neo4j import Neo4jGraph
            graph = Neo4jGraph(
                url=os.getenv("NEO4J_URI"),
                username=os.getenv("NEO4J_USERNAME"),
                password=os.getenv("NEO4J_PASSWORD"),
                database=os.getenv("NEO4J_DATABASE", "neo4j")
            )
        
        results = graph.query(cypher)
        
        # 4. ê²°ê³¼ í¬ë§·íŒ…
        if not results:
            answer = f"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ({explanation})"
        elif len(results) == 1:
            answer = _format_single_result(results[0], explanation)
        else:
            answer = _format_multiple_results(results, explanation)
        
        return {
            "question": question,
            "cypher": cypher,
            "results": results,
            "answer": answer,
            "success": True
        }
        
    except Exception as e:
        return {
            "question": question,
            "cypher": None,
            "results": None,
            "answer": f"âš ï¸ ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
            "success": False
        }


def _format_single_result(result: Dict, explanation: str) -> str:
    """ë‹¨ì¼ ê²°ê³¼ í¬ë§·íŒ…"""
    parts = []
    for key, value in result.items():
        if value is not None:
            parts.append(f"{key}: {value}")
    return " | ".join(parts) if parts else explanation


def _format_multiple_results(results: list, explanation: str) -> str:
    """ë‹¤ì¤‘ ê²°ê³¼ í¬ë§·íŒ…"""
    lines = [f"ğŸ“Š {len(results)}ê±´ ì¡°íšŒë¨:"]
    for i, r in enumerate(results[:10], 1):
        parts = [f"{v}" for v in r.values() if v is not None]
        lines.append(f"  {i}. {' | '.join(parts[:3])}")
    if len(results) > 10:
        lines.append(f"  ... ì™¸ {len(results) - 10}ê±´")
    return "\n".join(lines)


def ask_graph(question: str) -> str:
    """
    ğŸ† ê°„í¸ ì¸í„°í˜ì´ìŠ¤ - ì§ˆë¬¸í•˜ê³  ë‹µë³€ë§Œ ë°›ê¸°
    """
    result = text2cypher(question)
    return result["answer"]


if __name__ == "__main__":
    print(f"ğŸ¤– AI Service Status: {'âœ… í™œì„±í™”' if AI_AVAILABLE else 'âŒ ë¹„í™œì„±í™”'}")
    print(f"ğŸ“Œ Model: {MODEL}")
    
    if AI_AVAILABLE:
        # Prediction Test
        print("\nğŸ§ª Prediction í…ŒìŠ¤íŠ¸:")
        pred = predict_risk_trajectory("í…ŒìŠ¤íŠ¸ê¸°ì—…", 60, "ê²€ì°° ì••ìˆ˜ìˆ˜ìƒ‰ ì‹œì‘ ë° ì£¼ê°€ ê¸‰ë½")
        import json
        print(json.dumps(pred, indent=2, ensure_ascii=False))

