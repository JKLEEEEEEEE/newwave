"""
============================================================================
ìë™ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬ (V3)
============================================================================
- APScheduler ê¸°ë°˜ ì£¼ê¸°ì  ë°ì´í„° ìˆ˜ì§‘
- DART ê³µì‹œ, ë‰´ìŠ¤ ìë™ ìˆ˜ì§‘
- ë¦¬ìŠ¤í¬ ì ìˆ˜ ìë™ ê°±ì‹ 
"""

import os
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Optional, Callable, Dict, List, Any
from dataclasses import dataclass, field
from enum import Enum

# APScheduler (ì„ íƒì )
try:
    from apscheduler.schedulers.asyncio import AsyncIOScheduler
    from apscheduler.triggers.cron import CronTrigger
    from apscheduler.triggers.interval import IntervalTrigger
    APSCHEDULER_AVAILABLE = True
except ImportError:
    APSCHEDULER_AVAILABLE = False
    AsyncIOScheduler = None
    CronTrigger = None
    IntervalTrigger = None

from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=os.getenv("LOG_LEVEL", "INFO"))
logger = logging.getLogger(__name__)


class JobType(str, Enum):
    """ì‘ì—… ìœ í˜•"""
    DART_COLLECT = "dart_collect"
    NEWS_COLLECT = "news_collect"
    SCORE_UPDATE = "score_update"
    FULL_SYNC = "full_sync"
    HEALTH_CHECK = "health_check"


@dataclass
class JobConfig:
    """ì‘ì—… ì„¤ì •"""
    job_type: JobType
    interval_minutes: int = 60
    cron_expression: Optional[str] = None
    enabled: bool = True
    max_retries: int = 3
    timeout_seconds: int = 300


@dataclass
class JobResult:
    """ì‘ì—… ê²°ê³¼"""
    job_type: JobType
    success: bool
    started_at: datetime
    completed_at: datetime
    duration_seconds: float
    items_processed: int = 0
    errors: List[str] = field(default_factory=list)
    details: Dict[str, Any] = field(default_factory=dict)


class CollectionScheduler:
    """
    ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬

    Usage:
        scheduler = CollectionScheduler()
        scheduler.start()
        # ...
        scheduler.stop()
    """

    # ê¸°ë³¸ ìŠ¤ì¼€ì¤„ ì„¤ì •
    DEFAULT_SCHEDULES = {
        JobType.DART_COLLECT: JobConfig(
            job_type=JobType.DART_COLLECT,
            interval_minutes=60,  # 1ì‹œê°„ë§ˆë‹¤
            enabled=True
        ),
        JobType.NEWS_COLLECT: JobConfig(
            job_type=JobType.NEWS_COLLECT,
            interval_minutes=30,  # 30ë¶„ë§ˆë‹¤
            enabled=True
        ),
        JobType.SCORE_UPDATE: JobConfig(
            job_type=JobType.SCORE_UPDATE,
            interval_minutes=15,  # 15ë¶„ë§ˆë‹¤
            enabled=True
        ),
        JobType.FULL_SYNC: JobConfig(
            job_type=JobType.FULL_SYNC,
            cron_expression="0 6 * * *",  # ë§¤ì¼ 06:00
            enabled=True
        ),
        JobType.HEALTH_CHECK: JobConfig(
            job_type=JobType.HEALTH_CHECK,
            interval_minutes=5,  # 5ë¶„ë§ˆë‹¤
            enabled=True
        ),
    }

    def __init__(self, neo4j_client=None):
        self.neo4j_client = neo4j_client
        self.scheduler: Optional[AsyncIOScheduler] = None
        self.is_running = False
        self.job_history: List[JobResult] = []
        self.max_history = 100
        self._collectors_loaded = False

        # ìˆ˜ì§‘ê¸° ë¡œë“œ
        self._load_collectors()

    def _load_collectors(self):
        """ìˆ˜ì§‘ê¸° ëª¨ë“ˆ ë¡œë“œ"""
        try:
            from .dart_collector_v2 import DartCollectorV2
            from .news_collector_v2 import NewsCollectorV2
            from .risk_calculator_v3 import RiskCalculatorV3

            self.dart_collector = DartCollectorV2()
            self.news_collector = NewsCollectorV2()
            self.risk_calculator = RiskCalculatorV3(self.neo4j_client) if self.neo4j_client else None
            self._collectors_loaded = True
            logger.info("âœ… ìˆ˜ì§‘ê¸° ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
        except ImportError as e:
            logger.warning(f"âš ï¸ ìˆ˜ì§‘ê¸° ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.dart_collector = None
            self.news_collector = None
            self.risk_calculator = None

    @property
    def is_available(self) -> bool:
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
        return APSCHEDULER_AVAILABLE

    def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        if not APSCHEDULER_AVAILABLE:
            logger.warning("âš ï¸ APScheduler ë¯¸ì„¤ì¹˜. pip install apscheduler")
            return False

        if self.is_running:
            logger.warning("âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return False

        try:
            self.scheduler = AsyncIOScheduler()

            # ê¸°ë³¸ ì‘ì—… ë“±ë¡
            for job_type, config in self.DEFAULT_SCHEDULES.items():
                if config.enabled:
                    self._add_job(config)

            self.scheduler.start()
            self.is_running = True
            logger.info("ğŸš€ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨")
            return True

        except Exception as e:
            logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {e}")
            return False

    def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        if self.scheduler and self.is_running:
            self.scheduler.shutdown(wait=False)
            self.is_running = False
            logger.info("ğŸ›‘ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ë¨")

    def _add_job(self, config: JobConfig):
        """ì‘ì—… ì¶”ê°€"""
        if not self.scheduler:
            return

        job_func = self._get_job_function(config.job_type)
        if not job_func:
            logger.warning(f"âš ï¸ ì‘ì—… í•¨ìˆ˜ ì—†ìŒ: {config.job_type}")
            return

        job_id = f"job_{config.job_type.value}"

        if config.cron_expression:
            # Cron ê¸°ë°˜ ìŠ¤ì¼€ì¤„
            trigger = CronTrigger.from_crontab(config.cron_expression)
        else:
            # Interval ê¸°ë°˜ ìŠ¤ì¼€ì¤„
            trigger = IntervalTrigger(minutes=config.interval_minutes)

        self.scheduler.add_job(
            job_func,
            trigger=trigger,
            id=job_id,
            name=config.job_type.value,
            max_instances=1,
            replace_existing=True
        )

        logger.info(f"ğŸ“‹ ì‘ì—… ë“±ë¡: {config.job_type.value}")

    def _get_job_function(self, job_type: JobType) -> Optional[Callable]:
        """ì‘ì—… ìœ í˜•ì— ë§ëŠ” í•¨ìˆ˜ ë°˜í™˜"""
        job_map = {
            JobType.DART_COLLECT: self._job_dart_collect,
            JobType.NEWS_COLLECT: self._job_news_collect,
            JobType.SCORE_UPDATE: self._job_score_update,
            JobType.FULL_SYNC: self._job_full_sync,
            JobType.HEALTH_CHECK: self._job_health_check,
        }
        return job_map.get(job_type)

    async def _job_dart_collect(self):
        """DART ê³µì‹œ ìˆ˜ì§‘ ì‘ì—…"""
        started_at = datetime.now()
        errors = []
        items_processed = 0

        try:
            if not self.dart_collector:
                raise Exception("DART ìˆ˜ì§‘ê¸° ë¯¸ë¡œë“œ")

            # ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ ê¸°ì—… ì¡°íšŒ
            companies = await self._get_monitored_companies()

            for company in companies:
                try:
                    corp_code = company.get("corpCode")
                    if not corp_code:
                        continue

                    result = self.dart_collector.collect_disclosures(corp_code, days=1)
                    items_processed += result.total_count

                    # ë¦¬ìŠ¤í¬ ì‹ í˜¸ ì €ì¥
                    if result.risk_count > 0 and self.neo4j_client:
                        await self._save_signals(company["id"], result.items, "DART")

                except Exception as e:
                    errors.append(f"{company.get('name', 'Unknown')}: {str(e)}")

            success = len(errors) == 0

        except Exception as e:
            logger.error(f"DART ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            errors.append(str(e))
            success = False

        self._record_result(JobResult(
            job_type=JobType.DART_COLLECT,
            success=success,
            started_at=started_at,
            completed_at=datetime.now(),
            duration_seconds=(datetime.now() - started_at).total_seconds(),
            items_processed=items_processed,
            errors=errors
        ))

    async def _job_news_collect(self):
        """ë‰´ìŠ¤ ìˆ˜ì§‘ ì‘ì—…"""
        started_at = datetime.now()
        errors = []
        items_processed = 0

        try:
            if not self.news_collector:
                raise Exception("ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ë¯¸ë¡œë“œ")

            companies = await self._get_monitored_companies()

            for company in companies:
                try:
                    result = self.news_collector.collect_news(
                        company_name=company.get("name", ""),
                        limit=10
                    )
                    items_processed += result.total_count

                    if result.risk_count > 0 and self.neo4j_client:
                        await self._save_signals(company["id"], result.items, "NEWS")

                except Exception as e:
                    errors.append(f"{company.get('name', 'Unknown')}: {str(e)}")

            success = len(errors) == 0

        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            errors.append(str(e))
            success = False

        self._record_result(JobResult(
            job_type=JobType.NEWS_COLLECT,
            success=success,
            started_at=started_at,
            completed_at=datetime.now(),
            duration_seconds=(datetime.now() - started_at).total_seconds(),
            items_processed=items_processed,
            errors=errors
        ))

    async def _job_score_update(self):
        """ë¦¬ìŠ¤í¬ ì ìˆ˜ ê°±ì‹  ì‘ì—…"""
        started_at = datetime.now()
        errors = []
        items_processed = 0

        try:
            if not self.risk_calculator:
                raise Exception("ë¦¬ìŠ¤í¬ ê³„ì‚°ê¸° ë¯¸ë¡œë“œ")

            companies = await self._get_monitored_companies()

            for company in companies:
                try:
                    breakdown = self.risk_calculator.calculate_total_risk(company["id"])

                    # Neo4jì— ì ìˆ˜ ì €ì¥
                    if self.neo4j_client:
                        await self._update_company_score(
                            company["id"],
                            breakdown.total_score,
                            breakdown.status
                        )

                    items_processed += 1

                except Exception as e:
                    errors.append(f"{company.get('name', 'Unknown')}: {str(e)}")

            success = len(errors) == 0

        except Exception as e:
            logger.error(f"ì ìˆ˜ ê°±ì‹  ì‹¤íŒ¨: {e}")
            errors.append(str(e))
            success = False

        self._record_result(JobResult(
            job_type=JobType.SCORE_UPDATE,
            success=success,
            started_at=started_at,
            completed_at=datetime.now(),
            duration_seconds=(datetime.now() - started_at).total_seconds(),
            items_processed=items_processed,
            errors=errors
        ))

    async def _job_full_sync(self):
        """ì „ì²´ ë™ê¸°í™” ì‘ì—… (ë§¤ì¼ 06:00)"""
        started_at = datetime.now()
        errors = []
        details = {}

        try:
            # DART ì „ì²´ ìˆ˜ì§‘
            await self._job_dart_collect()
            details["dart"] = "completed"

            # ë‰´ìŠ¤ ì „ì²´ ìˆ˜ì§‘
            await self._job_news_collect()
            details["news"] = "completed"

            # ì ìˆ˜ ì „ì²´ ê°±ì‹ 
            await self._job_score_update()
            details["scores"] = "completed"

            success = True
            logger.info("âœ… ì „ì²´ ë™ê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"ì „ì²´ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            errors.append(str(e))
            success = False

        self._record_result(JobResult(
            job_type=JobType.FULL_SYNC,
            success=success,
            started_at=started_at,
            completed_at=datetime.now(),
            duration_seconds=(datetime.now() - started_at).total_seconds(),
            errors=errors,
            details=details
        ))

    async def _job_health_check(self):
        """í—¬ìŠ¤ ì²´í¬ ì‘ì—…"""
        started_at = datetime.now()
        errors = []
        details = {}

        try:
            # Neo4j ì—°ê²° í™•ì¸
            if self.neo4j_client:
                try:
                    self.neo4j_client.execute_read("RETURN 1 AS check")
                    details["neo4j"] = "healthy"
                except Exception as e:
                    details["neo4j"] = f"unhealthy: {e}"
                    errors.append(f"Neo4j: {e}")

            # ìˆ˜ì§‘ê¸° ìƒíƒœ í™•ì¸
            details["dart_collector"] = "available" if self.dart_collector else "unavailable"
            details["news_collector"] = "available" if self.news_collector else "unavailable"
            details["risk_calculator"] = "available" if self.risk_calculator else "unavailable"

            success = len(errors) == 0

        except Exception as e:
            errors.append(str(e))
            success = False

        self._record_result(JobResult(
            job_type=JobType.HEALTH_CHECK,
            success=success,
            started_at=started_at,
            completed_at=datetime.now(),
            duration_seconds=(datetime.now() - started_at).total_seconds(),
            errors=errors,
            details=details
        ))

    async def _get_monitored_companies(self) -> List[Dict]:
        """ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ ê¸°ì—… ëª©ë¡ ì¡°íšŒ"""
        if not self.neo4j_client:
            # Mock ë°ì´í„°
            return [
                {"id": "sk_hynix", "name": "SKí•˜ì´ë‹‰ìŠ¤", "corpCode": "00126380"},
                {"id": "samsung", "name": "ì‚¼ì„±ì „ì", "corpCode": "00126380"},
                {"id": "hanmi", "name": "í•œë¯¸ë°˜ë„ì²´", "corpCode": "00156225"},
            ]

        try:
            query = """
            MATCH (c:Company)
            WHERE c.isMonitored = true OR c.isMonitored IS NULL
            RETURN c.id AS id, c.name AS name, c.corpCode AS corpCode
            LIMIT 100
            """
            results = self.neo4j_client.execute_read(query)
            return [dict(r) for r in results]
        except Exception as e:
            logger.error(f"ê¸°ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    async def _save_signals(self, company_id: str, items: List, source: str):
        """ë¦¬ìŠ¤í¬ ì‹ í˜¸ ì €ì¥"""
        if not self.neo4j_client:
            return

        for item in items:
            if not hasattr(item, "risk_score") or item.risk_score <= 0:
                continue

            try:
                query = """
                MATCH (c:Company {id: $companyId})
                CREATE (sig:Signal {
                    id: $signalId,
                    source: $source,
                    title: $title,
                    riskScore: $score,
                    keywords: $keywords,
                    detectedAt: datetime()
                })
                CREATE (sig)-[:DETECTED_IN]->(c)
                """
                self.neo4j_client.execute_write(query, {
                    "companyId": company_id,
                    "signalId": f"{source}_{item.id}",
                    "source": source,
                    "title": getattr(item, "title", ""),
                    "score": item.risk_score,
                    "keywords": getattr(item, "matched_keywords", [])
                })
            except Exception as e:
                logger.warning(f"ì‹ í˜¸ ì €ì¥ ì‹¤íŒ¨: {e}")

    async def _update_company_score(self, company_id: str, score: int, status: str):
        """ê¸°ì—… ì ìˆ˜ ì—…ë°ì´íŠ¸"""
        if not self.neo4j_client:
            return

        try:
            query = """
            MATCH (c:Company {id: $companyId})
            SET c.totalRiskScore = $score,
                c.riskLevel = $status,
                c.lastScoreUpdate = datetime()
            WITH c
            MATCH (s:Status {id: $status})
            MERGE (c)-[:HAS_STATUS]->(s)
            """
            self.neo4j_client.execute_write(query, {
                "companyId": company_id,
                "score": score,
                "status": status
            })
        except Exception as e:
            logger.warning(f"ì ìˆ˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def _record_result(self, result: JobResult):
        """ì‘ì—… ê²°ê³¼ ê¸°ë¡"""
        self.job_history.append(result)

        # ì´ë ¥ í¬ê¸° ì œí•œ
        if len(self.job_history) > self.max_history:
            self.job_history = self.job_history[-self.max_history:]

        # ë¡œê¹…
        status = "âœ…" if result.success else "âŒ"
        logger.info(
            f"{status} {result.job_type.value}: "
            f"{result.items_processed} items, "
            f"{result.duration_seconds:.2f}s"
        )

    def get_job_status(self) -> Dict:
        """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
        if not self.scheduler:
            return {"running": False, "jobs": []}

        jobs = []
        for job in self.scheduler.get_jobs():
            jobs.append({
                "id": job.id,
                "name": job.name,
                "next_run": job.next_run_time.isoformat() if job.next_run_time else None,
                "pending": job.pending
            })

        return {
            "running": self.is_running,
            "jobs": jobs,
            "recent_results": [
                {
                    "job_type": r.job_type.value,
                    "success": r.success,
                    "completed_at": r.completed_at.isoformat(),
                    "duration": r.duration_seconds,
                    "items": r.items_processed
                }
                for r in self.job_history[-10:]
            ]
        }

    def trigger_job(self, job_type: JobType) -> bool:
        """ì‘ì—… ìˆ˜ë™ ì‹¤í–‰"""
        if not self.scheduler or not self.is_running:
            return False

        job_id = f"job_{job_type.value}"
        job = self.scheduler.get_job(job_id)

        if job:
            job.modify(next_run_time=datetime.now())
            return True

        return False

    def update_schedule(self, job_type: JobType, interval_minutes: int = None, enabled: bool = None):
        """ìŠ¤ì¼€ì¤„ ì„¤ì • ë³€ê²½"""
        if job_type not in self.DEFAULT_SCHEDULES:
            return False

        config = self.DEFAULT_SCHEDULES[job_type]

        if interval_minutes is not None:
            config.interval_minutes = interval_minutes

        if enabled is not None:
            config.enabled = enabled

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì¬ë“±ë¡
        if self.scheduler and self.is_running:
            job_id = f"job_{job_type.value}"

            # ê¸°ì¡´ ì‘ì—… ì œê±°
            if self.scheduler.get_job(job_id):
                self.scheduler.remove_job(job_id)

            # ìƒˆ ì„¤ì •ìœ¼ë¡œ ë“±ë¡
            if config.enabled:
                self._add_job(config)

        return True


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
scheduler: Optional[CollectionScheduler] = None


def get_scheduler(neo4j_client=None) -> CollectionScheduler:
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global scheduler
    if scheduler is None:
        scheduler = CollectionScheduler(neo4j_client)
    return scheduler


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import asyncio

    async def test():
        sched = CollectionScheduler()

        if sched.is_available:
            sched.start()
            print("ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨")
            print(sched.get_job_status())

            await asyncio.sleep(10)

            sched.stop()
            print("ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œë¨")
        else:
            print("APScheduler ë¯¸ì„¤ì¹˜")

    asyncio.run(test())
